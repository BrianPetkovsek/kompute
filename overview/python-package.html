
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <meta name="viewport" content="width=device-width,initial-scale=1">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <meta name="lang:clipboard.copy" content="Copy to clipboard">
  <meta name="lang:clipboard.copied" content="Copied to clipboard">
  <meta name="lang:search.language" content="en">
  <meta name="lang:search.pipeline.stopwords" content="True">
  <meta name="lang:search.pipeline.trimmer" content="True">
  <meta name="lang:search.result.none" content="No matching documents">
  <meta name="lang:search.result.one" content="1 matching document">
  <meta name="lang:search.result.other" content="# matching documents">
  <meta name="lang:search.tokenizer" content="[\s\-]+">

  
    <link href="https://fonts.gstatic.com/" rel="preconnect" crossorigin>
    <link href="https://fonts.googleapis.com/css?family=Roboto+Mono:400,500,700|Roboto:300,400,400i,700&display=fallback" rel="stylesheet">

    <style>
      body,
      input {
        font-family: "Roboto", "Helvetica Neue", Helvetica, Arial, sans-serif
      }

      code,
      kbd,
      pre {
        font-family: "Roboto Mono", "Courier New", Courier, monospace
      }
    </style>
  

  <link rel="stylesheet" href="../_static/stylesheets/application.css"/>
  <link rel="stylesheet" href="../_static/stylesheets/application-palette.css"/>
  <link rel="stylesheet" href="../_static/stylesheets/application-fixes.css"/>
  
  <link rel="stylesheet" href="../_static/fonts/material-icons.css"/>
  
  <meta name="theme-color" content="#3f51b5">
  <script src="../_static/javascripts/modernizr.js"></script>
  
  
  
    <title>Python Package Overview &#8212; Vulkan Kompute 0.5.1 documentation</title>
    <link rel="stylesheet" href="../_static/material.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/language_data.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Asynchronous and Parallel Operations" href="async-parallel.html" />
    <link rel="prev" title="Examples" href="advanced-examples.html" />
  
   

  </head>
  <body dir=ltr
        data-md-color-primary=red data-md-color-accent=light-blue>
  
  <svg class="md-svg">
    <defs data-children-count="0">
      
      <svg xmlns="http://www.w3.org/2000/svg" width="416" height="448" viewBox="0 0 416 448" id="__github"><path fill="currentColor" d="M160 304q0 10-3.125 20.5t-10.75 19T128 352t-18.125-8.5-10.75-19T96 304t3.125-20.5 10.75-19T128 256t18.125 8.5 10.75 19T160 304zm160 0q0 10-3.125 20.5t-10.75 19T288 352t-18.125-8.5-10.75-19T256 304t3.125-20.5 10.75-19T288 256t18.125 8.5 10.75 19T320 304zm40 0q0-30-17.25-51T296 232q-10.25 0-48.75 5.25Q229.5 240 208 240t-39.25-2.75Q130.75 232 120 232q-29.5 0-46.75 21T56 304q0 22 8 38.375t20.25 25.75 30.5 15 35 7.375 37.25 1.75h42q20.5 0 37.25-1.75t35-7.375 30.5-15 20.25-25.75T360 304zm56-44q0 51.75-15.25 82.75-9.5 19.25-26.375 33.25t-35.25 21.5-42.5 11.875-42.875 5.5T212 416q-19.5 0-35.5-.75t-36.875-3.125-38.125-7.5-34.25-12.875T37 371.5t-21.5-28.75Q0 312 0 260q0-59.25 34-99-6.75-20.5-6.75-42.5 0-29 12.75-54.5 27 0 47.5 9.875t47.25 30.875Q171.5 96 212 96q37 0 70 8 26.25-20.5 46.75-30.25T376 64q12.75 25.5 12.75 54.5 0 21.75-6.75 42 34 40 34 99.5z"/></svg>
      
    </defs>
  </svg>
  
  <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer">
  <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search">
  <label class="md-overlay" data-md-component="overlay" for="__drawer"></label>
  <a href="#overview/python-package" tabindex="1" class="md-skip"> Skip to content </a>
  <header class="md-header" data-md-component="header">
  <nav class="md-header-nav md-grid">
    <div class="md-flex navheader">
      <div class="md-flex__cell md-flex__cell--shrink">
        <a href="../index.html" title="Vulkan Kompute 0.5.1 documentation"
           class="md-header-nav__button md-logo">
          
            &nbsp;
          
        </a>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        <label class="md-icon md-icon--menu md-header-nav__button" for="__drawer"></label>
      </div>
      <div class="md-flex__cell md-flex__cell--stretch">
        <div class="md-flex__ellipsis md-header-nav__title" data-md-component="title">
          <span class="md-header-nav__topic">Vulkan Kompute</span>
          <span class="md-header-nav__topic"> Python Package Overview </span>
        </div>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        <label class="md-icon md-icon--search md-header-nav__button" for="__search"></label>
        
<div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" action="../search.html" method="GET" name="search">
      <input type="text" class="md-search__input" name="q" placeholder="Search"
             autocapitalize="off" autocomplete="off" spellcheck="false"
             data-md-component="query" data-md-state="active">
      <label class="md-icon md-search__icon" for="__search"></label>
      <button type="reset" class="md-icon md-search__icon" data-md-component="reset" tabindex="-1">
        &#xE5CD;
      </button>
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="result">
          <div class="md-search-result__meta">
            Type to start searching
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>

      </div>
      
        <div class="md-flex__cell md-flex__cell--shrink">
          <div class="md-header-nav__source">
            <a href="https://github.com/EthicalML/vulkan-kompute/" title="Go to repository" class="md-source" data-md-source="github">

    <div class="md-source__icon">
      <svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 24 24" width="28" height="28">
        <use xlink:href="#__github" width="24" height="24"></use>
      </svg>
    </div>
  
  <div class="md-source__repository">
    Vulkan Kompute
  </div>
</a>
          </div>
        </div>
      
      
  
  <script src="../_static/javascripts/version_dropdown.js"></script>
  <script>
    var json_loc = "../"versions.json"",
        target_loc = "../../",
        text = "Versions";
    $( document ).ready( add_version_dropdown(json_loc, target_loc, text));
  </script>
  

    </div>
  </nav>
</header>

  
  <div class="md-container">
    
    
    
  <nav class="md-tabs" data-md-component="tabs">
    <div class="md-tabs__inner md-grid">
      <ul class="md-tabs__list">
          <li class="md-tabs__item"><a href="../index.html" class="md-tabs__link">Vulkan Kompute 0.5.1 documentation</a></li>
      </ul>
    </div>
  </nav>
    <main class="md-main">
      <div class="md-main__inner md-grid" data-md-component="container">
        
          <div class="md-sidebar md-sidebar--primary" data-md-component="navigation">
            <div class="md-sidebar__scrollwrap">
              <div class="md-sidebar__inner">
                <nav class="md-nav md-nav--primary" data-md-level="0">
  <label class="md-nav__title md-nav__title--site" for="__drawer">
    <a href="../index.html" title="Vulkan Kompute 0.5.1 documentation" class="md-nav__button md-logo">
      
        <img src="../_static/" alt=" logo" width="48" height="48">
      
    </a>
    <a href="../index.html"
       title="Vulkan Kompute 0.5.1 documentation">Vulkan Kompute</a>
  </label>
    <div class="md-nav__source">
      <a href="https://github.com/EthicalML/vulkan-kompute/" title="Go to repository" class="md-source" data-md-source="github">

    <div class="md-source__icon">
      <svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 24 24" width="28" height="28">
        <use xlink:href="#__github" width="24" height="24"></use>
      </svg>
    </div>
  
  <div class="md-source__repository">
    Vulkan Kompute
  </div>
</a>
    </div>
  
  

  
  <ul class="md-nav__list">
    <li class="md-nav__item">
    
    
      <a href="advanced-examples.html" class="md-nav__link">Simple & Advanced Examples</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
    <input class="md-toggle md-nav__toggle" data-md-toggle="toc" type="checkbox" id="__toc">
    <label class="md-nav__link md-nav__link--active" for="__toc"> Python Package Overview </label>
    
      <a href="#" class="md-nav__link md-nav__link--active">Python Package Overview</a>
      
        
<nav class="md-nav md-nav--secondary">
  <ul class="md-nav__list" data-md-scrollfix="">
    
<li class="md-nav__item"><a class="md-nav__extra_link" href="../_sources/overview/python-package.rst.txt">Show Source</a> </li>

  </ul>
</nav>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="async-parallel.html" class="md-nav__link">Asynchronous & Parallel Operations</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="memory-management.html" class="md-nav__link">Memory Management Principles</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="build-system.html" class="md-nav__link">Build System Deep Dive</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="shaders-to-headers.html" class="md-nav__link">Converting GLSL/HLSL Shaders to C++ Headers</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="mobile-android.html" class="md-nav__link">Mobile App Integration (Android)</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="game-engine-godot.html" class="md-nav__link">Game Engine Integration (Godot Engine)</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="python-reference.html" class="md-nav__link">Python Class Documentation & Reference</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="reference.html" class="md-nav__link">C++ Class Documentation & Reference</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../genindex.html" class="md-nav__link">Code Index</a>
      
    
    </li>
  </ul>
  

</nav>
              </div>
            </div>
          </div>
          <div class="md-sidebar md-sidebar--secondary" data-md-component="toc">
            <div class="md-sidebar__scrollwrap">
              <div class="md-sidebar__inner">
                
<nav class="md-nav md-nav--secondary">
  <ul class="md-nav__list" data-md-scrollfix="">
    
<li class="md-nav__item"><a class="md-nav__extra_link" href="../_sources/overview/python-package.rst.txt">Show Source</a> </li>

<li id="searchbox" class="md-nav__item"></li>

  </ul>
</nav>
              </div>
            </div>
          </div>
        
        <div class="md-content">
          <article class="md-content__inner md-typeset" role="main">
            
  
<h1 id="overview-python-package--page-root">Python Package Overview<a class="headerlink" href="#overview-python-package--page-root" title="Permalink to this headline">¶</a></h1>
<p>This section provides an overview of the Python Package from a functionality perspective. If you wish to see all the classes and their respective functions you can find that in the <a class="reference external" href="python-reference.html">Python Class Reference Section</a>.</p>
<p>Below is a diagram that provides insights on the relationship between Vulkan Kompute objects and Vulkan resources, which primarily encompass ownership of either CPU and/or GPU memory.</p>
<a class="reference internal image-reference" href="../_images/kompute-architecture.jpg"><img alt="../_images/kompute-architecture.jpg" src="../_images/kompute-architecture.jpg" style="width: 70%;"/></a>

<h2 id="package-installation">Package Installation<a class="headerlink" href="#package-installation" title="Permalink to this headline">¶</a></h2>
<p>Make sure you have the following dependencies installed:</p>
<ul class="simple">
<li><p>CMAKE v3.41+ (install in <a class="reference external" href="https://tulip.labri.fr/TulipDrupal/?q=node/1081">Windows</a>, <a class="reference external" href="https://vitux.com/how-to-install-cmake-on-ubuntu-18-04/">Linux (Ubuntu)</a>, <a class="reference external" href="https://medium.com/r?url=https%3A%2F%2Fstackoverflow.com%2Fa%2F59825656%2F1889253">Mac</a>)</p></li>
<li><p>Vulkan SDK installed via <a class="reference external" href="https://vulkan.lunarg.com/sdk/home">official website</a></p></li>
<li><p>C++ compiler (eg. gcc for linux / mac, MSVC for Windows)</p></li>
</ul>
<p>Once you set up the package dependencies, you can install Kompute from <code class="docutils literal notranslate"><span class="pre">`Pypi`</span></code> using <code class="docutils literal notranslate"><span class="pre">`pip`</span></code> by running:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>pip install kp
</pre></div>
</div>
<p>You can also install from master branch using:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">pip</span> <span class="n">install</span> <span class="n">git</span><span class="o">+</span><span class="n">git</span><span class="p">:</span><span class="o">//</span><span class="n">github</span><span class="o">.</span><span class="n">com</span><span class="o">/</span><span class="n">EthicalML</span><span class="o">/</span><span class="n">vulkan</span><span class="o">-</span><span class="n">kompute</span><span class="o">.</span><span class="n">git</span><span class="nd">@master</span>
</pre></div>
</div>


<h2 id="core-python-components">Core Python Components<a class="headerlink" href="#core-python-components" title="Permalink to this headline">¶</a></h2>
<p>The Python package exposes three main classes:</p>
<ul class="simple">
<li><p><a class="reference internal" href="python-reference.html#kp.Manager" title="kp.Manager"><code class="xref py py-class docutils literal notranslate"><span class="pre">kp.Manager</span></code></a> - Manages all high level Vulkan and Kompute resources created</p></li>
<li><p><a class="reference internal" href="python-reference.html#kp.Sequence" title="kp.Sequence"><code class="xref py py-class docutils literal notranslate"><span class="pre">kp.Sequence</span></code></a> - Contains a set of recorded operations that can be reused</p></li>
<li><p><a class="reference internal" href="python-reference.html#id0" title="kp.Tensor"><code class="xref py py-class docutils literal notranslate"><span class="pre">kp.Tensor</span></code></a> - Core data component to manage GPU and host data used in operations</p></li>
</ul>
<p>One thing that you will notice is that the class <code class="xref py py-class docutils literal notranslate"><span class="pre">kp::OpBase</span></code> and all its relevant operator subclasses are not exposed in Python.</p>
<p>This is primarily because the way to interact with the operations are through the respective <a class="reference internal" href="python-reference.html#kp.Manager" title="kp.Manager"><code class="xref py py-class docutils literal notranslate"><span class="pre">kp.Manager</span></code></a> and <a class="reference internal" href="python-reference.html#kp.Sequence" title="kp.Sequence"><code class="xref py py-class docutils literal notranslate"><span class="pre">kp.Sequence</span></code></a> functions.</p>
<p>More specifically, it can be through the following functions:</p>
<ul class="simple">
<li><p>mgr.eval_&lt;opname&gt; - Runs operation under an existing named sequence</p></li>
<li><p>mgr.eval_&lt;opname&gt;_def - Runs operation under a new anonymous sequence</p></li>
<li><p>mgr.eval_async_&lt;opname&gt; - Runs operation asynchronously under an existing named sequence</p></li>
<li><p>mgr.eval_async_&lt;opname&gt;_def - Runs operation asynchronously under a new anonymous sequence</p></li>
<li><p>seq.record_&lt;opname&gt; - Records operation in sequence (requires sequence to be in recording mode)</p></li>
</ul>


<h2 id="python-examples">Python Examples<a class="headerlink" href="#python-examples" title="Permalink to this headline">¶</a></h2>
<p>Below we cover a broad set of examples. These use the <code class="docutils literal notranslate"><span class="pre">`pyshader`</span></code> dependency, which you can install with <cite>pip install pyshader</cite>.</p>


<h2 id="python-example-simple">Python Example (Simple)<a class="headerlink" href="#python-example-simple" title="Permalink to this headline">¶</a></h2>
<p>Then you can interact with it from your interpreter. Below is the same sample as above “Your First Kompute (Simple Version)” but in Python:</p>
<div class="highlight-python notranslate"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34</pre></div></td><td class="code"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">kp</span> <span class="kn">import</span> <span class="n">Manager</span><span class="p">,</span> <span class="n">Tensor</span>
<span class="kn">from</span> <span class="nn">pyshader</span> <span class="kn">import</span> <span class="n">python2shader</span><span class="p">,</span> <span class="n">ivec3</span><span class="p">,</span> <span class="n">f32</span><span class="p">,</span> <span class="n">Array</span>

<span class="n">mgr</span> <span class="o">=</span> <span class="n">Manager</span><span class="p">()</span>

<span class="c1"># Can be initialized with List[] or np.Array</span>
<span class="n">tensor_in_a</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
<span class="n">tensor_in_b</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
<span class="n">tensor_out</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span>

<span class="n">mgr</span><span class="o">.</span><span class="n">eval_tensor_create_def</span><span class="p">([</span><span class="n">tensor_in_a</span><span class="p">,</span> <span class="n">tensor_in_b</span><span class="p">,</span> <span class="n">tensor_out</span><span class="p">])</span>

<span class="c1"># Define the function via PyShader or directly as glsl string or spirv bytes</span>
<span class="nd">@python2shader</span>
<span class="k">def</span> <span class="nf">compute_shader_multiply</span><span class="p">(</span><span class="n">index</span><span class="o">=</span><span class="p">(</span><span class="s2">"input"</span><span class="p">,</span> <span class="s2">"GlobalInvocationId"</span><span class="p">,</span> <span class="n">ivec3</span><span class="p">),</span>
                            <span class="n">data1</span><span class="o">=</span><span class="p">(</span><span class="s2">"buffer"</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">Array</span><span class="p">(</span><span class="n">f32</span><span class="p">)),</span>
                            <span class="n">data2</span><span class="o">=</span><span class="p">(</span><span class="s2">"buffer"</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">Array</span><span class="p">(</span><span class="n">f32</span><span class="p">)),</span>
                            <span class="n">data3</span><span class="o">=</span><span class="p">(</span><span class="s2">"buffer"</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">Array</span><span class="p">(</span><span class="n">f32</span><span class="p">))):</span>
    <span class="n">i</span> <span class="o">=</span> <span class="n">index</span><span class="o">.</span><span class="n">x</span>
    <span class="n">data3</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">data1</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">*</span> <span class="n">data2</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>

<span class="c1"># Run shader operation synchronously</span>
<span class="n">mgr</span><span class="o">.</span><span class="n">eval_algo_data_def</span><span class="p">(</span>
    <span class="p">[</span><span class="n">tensor_in_a</span><span class="p">,</span> <span class="n">tensor_in_b</span><span class="p">,</span> <span class="n">tensor_out</span><span class="p">],</span> <span class="n">compute_shader_multiply</span><span class="o">.</span><span class="n">to_spirv</span><span class="p">())</span>

<span class="c1"># Alternatively can pass raw string/bytes:</span>
<span class="c1"># shaderFileData = """ shader code here... """</span>
<span class="c1"># mgr.eval_algo_data_def([tensor_in_a, tensor_in_b, tensor_out], list(shaderFileData))</span>

<span class="n">mgr</span><span class="o">.</span><span class="n">eval_await_def</span><span class="p">()</span>

<span class="n">mgr</span><span class="o">.</span><span class="n">eval_tensor_sync_local_def</span><span class="p">([</span><span class="n">tensor_out</span><span class="p">])</span>

<span class="k">assert</span> <span class="n">tensor_out</span><span class="o">.</span><span class="n">data</span><span class="p">()</span> <span class="o">==</span> <span class="p">[</span><span class="mf">2.0</span><span class="p">,</span> <span class="mf">4.0</span><span class="p">,</span> <span class="mf">6.0</span><span class="p">]</span>
</pre></div>
</td></tr></table></div>


<h2 id="python-example-extended">Python Example (Extended)<a class="headerlink" href="#python-example-extended" title="Permalink to this headline">¶</a></h2>
<p>Similarly you can find the same extended example as above:</p>
<div class="highlight-python notranslate"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37</pre></div></td><td class="code"><div class="highlight"><pre><span></span> <span class="kn">from</span> <span class="nn">kp</span> <span class="kn">import</span> <span class="n">Manager</span><span class="p">,</span> <span class="n">Tensor</span>
 <span class="kn">from</span> <span class="nn">pyshader</span> <span class="kn">import</span> <span class="n">python2shader</span><span class="p">,</span> <span class="n">ivec3</span><span class="p">,</span> <span class="n">f32</span><span class="p">,</span> <span class="n">Array</span>

 <span class="n">mgr</span> <span class="o">=</span> <span class="n">Manager</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="p">[</span><span class="mi">2</span><span class="p">])</span>

 <span class="c1"># Can be initialized with List[] or np.Array</span>
 <span class="n">tensor_in_a</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
 <span class="n">tensor_in_b</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
 <span class="n">tensor_out</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span>

 <span class="n">mgr</span><span class="o">.</span><span class="n">eval_tensor_create_def</span><span class="p">([</span><span class="n">tensor_in_a</span><span class="p">,</span> <span class="n">tensor_in_b</span><span class="p">,</span> <span class="n">tensor_out</span><span class="p">])</span>

 <span class="n">seq</span> <span class="o">=</span> <span class="n">mgr</span><span class="o">.</span><span class="n">create_sequence</span><span class="p">(</span><span class="s2">"op"</span><span class="p">)</span>

 <span class="c1"># Define the function via PyShader or directly as glsl string or spirv bytes</span>
 <span class="nd">@python2shader</span>
 <span class="k">def</span> <span class="nf">compute_shader_multiply</span><span class="p">(</span><span class="n">index</span><span class="o">=</span><span class="p">(</span><span class="s2">"input"</span><span class="p">,</span> <span class="s2">"GlobalInvocationId"</span><span class="p">,</span> <span class="n">ivec3</span><span class="p">),</span>
                             <span class="n">data1</span><span class="o">=</span><span class="p">(</span><span class="s2">"buffer"</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">Array</span><span class="p">(</span><span class="n">f32</span><span class="p">)),</span>
                             <span class="n">data2</span><span class="o">=</span><span class="p">(</span><span class="s2">"buffer"</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">Array</span><span class="p">(</span><span class="n">f32</span><span class="p">)),</span>
                             <span class="n">data3</span><span class="o">=</span><span class="p">(</span><span class="s2">"buffer"</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">Array</span><span class="p">(</span><span class="n">f32</span><span class="p">))):</span>
     <span class="n">i</span> <span class="o">=</span> <span class="n">index</span><span class="o">.</span><span class="n">x</span>
     <span class="n">data3</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">data1</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">*</span> <span class="n">data2</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>

 <span class="c1"># Run shader operation asynchronously and then await</span>
 <span class="n">mgr</span><span class="o">.</span><span class="n">eval_async_algo_data_def</span><span class="p">(</span>
     <span class="p">[</span><span class="n">tensor_in_a</span><span class="p">,</span> <span class="n">tensor_in_b</span><span class="p">,</span> <span class="n">tensor_out</span><span class="p">],</span> <span class="n">compute_shader_multiply</span><span class="o">.</span><span class="n">to_spirv</span><span class="p">())</span>
 <span class="n">mgr</span><span class="o">.</span><span class="n">eval_await_def</span><span class="p">()</span>

 <span class="n">seq</span><span class="o">.</span><span class="n">begin</span><span class="p">()</span>
 <span class="n">seq</span><span class="o">.</span><span class="n">record_tensor_sync_local</span><span class="p">([</span><span class="n">tensor_in_a</span><span class="p">])</span>
 <span class="n">seq</span><span class="o">.</span><span class="n">record_tensor_sync_local</span><span class="p">([</span><span class="n">tensor_in_b</span><span class="p">])</span>
 <span class="n">seq</span><span class="o">.</span><span class="n">record_tensor_sync_local</span><span class="p">([</span><span class="n">tensor_out</span><span class="p">])</span>
 <span class="n">seq</span><span class="o">.</span><span class="n">end</span><span class="p">()</span>

 <span class="n">seq</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>

 <span class="k">assert</span> <span class="n">tensor_out</span><span class="o">.</span><span class="n">data</span><span class="p">()</span> <span class="o">==</span> <span class="p">[</span><span class="mf">2.0</span><span class="p">,</span> <span class="mf">4.0</span><span class="p">,</span> <span class="mf">6.0</span><span class="p">]</span>
</pre></div>
</td></tr></table></div>


<h2 id="kompute-operation-capabilities">Kompute Operation Capabilities<a class="headerlink" href="#kompute-operation-capabilities" title="Permalink to this headline">¶</a></h2>
<p>Handling multiple capabilites of processing can be done by compute shaders being loaded into separate sequences. The example below shows how this can be done:</p>
<div class="highlight-python notranslate"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37</pre></div></td><td class="code"><div class="highlight"><pre><span></span> <span class="kn">from</span> <span class="nn">kp</span> <span class="kn">import</span> <span class="n">Manager</span>

 <span class="c1"># We'll assume we have the shader data available</span>
 <span class="kn">from</span> <span class="nn">my_spv_shader_data</span> <span class="kn">import</span> <span class="n">mult_shader</span><span class="p">,</span> <span class="n">sum_shader</span>

 <span class="n">mgr</span> <span class="o">=</span> <span class="n">Manager</span><span class="p">()</span>

 <span class="n">t1</span> <span class="o">=</span> <span class="n">mgr</span><span class="o">.</span><span class="n">build_tensor</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">])</span>
 <span class="n">t2</span> <span class="o">=</span> <span class="n">mgr</span><span class="o">.</span><span class="n">build_tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">])</span>
 <span class="n">t3</span> <span class="o">=</span> <span class="n">mgr</span><span class="o">.</span><span class="n">build_tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">])</span>

 <span class="c1"># Create multiple separate sequences</span>
 <span class="n">sq_mult</span> <span class="o">=</span> <span class="n">mgr</span><span class="o">.</span><span class="n">create_sequence</span><span class="p">(</span><span class="s2">"SQ_MULT"</span><span class="p">)</span>
 <span class="n">sq_sum</span> <span class="o">=</span> <span class="n">mgr</span><span class="o">.</span><span class="n">create_sequence</span><span class="p">(</span><span class="s2">"SQ_SUM"</span><span class="p">)</span>
 <span class="n">sq_sync</span> <span class="o">=</span> <span class="n">mgr</span><span class="o">.</span><span class="n">create_sequence</span><span class="p">(</span><span class="s2">"SQ_SYNC"</span><span class="p">)</span>

 <span class="c1"># Initialize sq_mult</span>
 <span class="n">sq_mult</span><span class="o">.</span><span class="n">begin</span><span class="p">()</span>
 <span class="n">sq_mult</span><span class="o">.</span><span class="n">record_algo_data</span><span class="p">([</span><span class="n">t1</span><span class="p">,</span> <span class="n">t2</span><span class="p">,</span> <span class="n">t3</span><span class="p">],</span> <span class="n">add_shader</span><span class="p">)</span>
 <span class="n">sq_mult</span><span class="o">.</span><span class="n">end</span><span class="p">()</span>

 <span class="n">sq_sum</span><span class="o">.</span><span class="n">begin</span><span class="p">()</span>
 <span class="n">sq_sum</span><span class="o">.</span><span class="n">record_algo_data</span><span class="p">([</span><span class="n">t3</span><span class="p">,</span> <span class="n">t2</span><span class="p">,</span> <span class="n">t1</span><span class="p">],</span> <span class="n">sum_shader</span><span class="p">)</span>
 <span class="n">sq_sum</span><span class="o">.</span><span class="n">end</span><span class="p">()</span>

 <span class="n">sq_sync</span><span class="o">.</span><span class="n">begin</span><span class="p">()</span>
 <span class="n">sq_sync</span><span class="o">.</span><span class="n">record_tensor_sync_local</span><span class="p">([</span><span class="n">t1</span><span class="p">,</span> <span class="n">t3</span><span class="p">])</span>
 <span class="n">sq_sync</span><span class="o">.</span><span class="n">end</span><span class="p">()</span>

 <span class="c1"># Run multiple iterations</span>
 <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">):</span>
     <span class="n">sq_mult</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
     <span class="n">sq_sum</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>

 <span class="n">sq_sync</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>

 <span class="nb">print</span><span class="p">(</span><span class="n">t1</span><span class="o">.</span><span class="n">data</span><span class="p">(),</span> <span class="n">t2</span><span class="o">.</span><span class="n">data</span><span class="p">(),</span> <span class="n">t3</span><span class="o">.</span><span class="n">data</span><span class="p">())</span>
</pre></div>
</td></tr></table></div>


<h2 id="machine-learning-logistic-regression-implementation">Machine Learning Logistic Regression Implementation<a class="headerlink" href="#machine-learning-logistic-regression-implementation" title="Permalink to this headline">¶</a></h2>
<p>Similar to the logistic regression implementation in the C++ examples section, below you can find the Python implementation of the Logistic Regression algorithm.</p>
<div class="highlight-python notranslate"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre>  1
  2
  3
  4
  5
  6
  7
  8
  9
 10
 11
 12
 13
 14
 15
 16
 17
 18
 19
 20
 21
 22
 23
 24
 25
 26
 27
 28
 29
 30
 31
 32
 33
 34
 35
 36
 37
 38
 39
 40
 41
 42
 43
 44
 45
 46
 47
 48
 49
 50
 51
 52
 53
 54
 55
 56
 57
 58
 59
 60
 61
 62
 63
 64
 65
 66
 67
 68
 69
 70
 71
 72
 73
 74
 75
 76
 77
 78
 79
 80
 81
 82
 83
 84
 85
 86
 87
 88
 89
 90
 91
 92
 93
 94
 95
 96
 97
 98
 99
100
101
102
103
104
105</pre></div></td><td class="code"><div class="highlight"><pre><span></span> <span class="kn">from</span> <span class="nn">kp</span> <span class="kn">import</span> <span class="n">Manager</span><span class="p">,</span> <span class="n">Tensor</span>
 <span class="kn">from</span> <span class="nn">pyshader</span> <span class="kn">import</span> <span class="n">python2shader</span><span class="p">,</span> <span class="n">ivec3</span><span class="p">,</span> <span class="n">f32</span><span class="p">,</span> <span class="n">Array</span>

 <span class="nd">@python2shader</span>
 <span class="k">def</span> <span class="nf">compute_shader</span><span class="p">(</span>
         <span class="n">index</span>   <span class="o">=</span> <span class="p">(</span><span class="s2">"input"</span><span class="p">,</span> <span class="s2">"GlobalInvocationId"</span><span class="p">,</span> <span class="n">ivec3</span><span class="p">),</span>
         <span class="n">x_i</span>     <span class="o">=</span> <span class="p">(</span><span class="s2">"buffer"</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">Array</span><span class="p">(</span><span class="n">f32</span><span class="p">)),</span>
         <span class="n">x_j</span>     <span class="o">=</span> <span class="p">(</span><span class="s2">"buffer"</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">Array</span><span class="p">(</span><span class="n">f32</span><span class="p">)),</span>
         <span class="n">y</span>       <span class="o">=</span> <span class="p">(</span><span class="s2">"buffer"</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">Array</span><span class="p">(</span><span class="n">f32</span><span class="p">)),</span>
         <span class="n">w_in</span>    <span class="o">=</span> <span class="p">(</span><span class="s2">"buffer"</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">Array</span><span class="p">(</span><span class="n">f32</span><span class="p">)),</span>
         <span class="n">w_out_i</span> <span class="o">=</span> <span class="p">(</span><span class="s2">"buffer"</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="n">Array</span><span class="p">(</span><span class="n">f32</span><span class="p">)),</span>
         <span class="n">w_out_j</span> <span class="o">=</span> <span class="p">(</span><span class="s2">"buffer"</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="n">Array</span><span class="p">(</span><span class="n">f32</span><span class="p">)),</span>
         <span class="n">b_in</span>    <span class="o">=</span> <span class="p">(</span><span class="s2">"buffer"</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="n">Array</span><span class="p">(</span><span class="n">f32</span><span class="p">)),</span>
         <span class="n">b_out</span>   <span class="o">=</span> <span class="p">(</span><span class="s2">"buffer"</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="n">Array</span><span class="p">(</span><span class="n">f32</span><span class="p">)),</span>
         <span class="n">l_out</span>   <span class="o">=</span> <span class="p">(</span><span class="s2">"buffer"</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="n">Array</span><span class="p">(</span><span class="n">f32</span><span class="p">)),</span>
         <span class="n">M</span>       <span class="o">=</span> <span class="p">(</span><span class="s2">"buffer"</span><span class="p">,</span> <span class="mi">9</span><span class="p">,</span> <span class="n">Array</span><span class="p">(</span><span class="n">f32</span><span class="p">))):</span>

     <span class="n">i</span> <span class="o">=</span> <span class="n">index</span><span class="o">.</span><span class="n">x</span>

     <span class="n">m</span> <span class="o">=</span> <span class="n">M</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

     <span class="n">w_curr</span> <span class="o">=</span> <span class="n">vec2</span><span class="p">(</span><span class="n">w_in</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">w_in</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
     <span class="n">b_curr</span> <span class="o">=</span> <span class="n">b_in</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

     <span class="n">x_curr</span> <span class="o">=</span> <span class="n">vec2</span><span class="p">(</span><span class="n">x_i</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">x_j</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
     <span class="n">y_curr</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>

     <span class="n">z_dot</span> <span class="o">=</span> <span class="n">w_curr</span> <span class="o">@</span> <span class="n">x_curr</span>
     <span class="n">z</span> <span class="o">=</span> <span class="n">z_dot</span> <span class="o">+</span> <span class="n">b_curr</span>
     <span class="n">y_hat</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">/</span> <span class="p">(</span><span class="mf">1.0</span> <span class="o">+</span> <span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">z</span><span class="p">))</span>

     <span class="n">d_z</span> <span class="o">=</span> <span class="n">y_hat</span> <span class="o">-</span> <span class="n">y_curr</span>
     <span class="n">d_w</span> <span class="o">=</span> <span class="p">(</span><span class="mf">1.0</span> <span class="o">/</span> <span class="n">m</span><span class="p">)</span> <span class="o">*</span> <span class="n">x_curr</span> <span class="o">*</span> <span class="n">d_z</span>
     <span class="n">d_b</span> <span class="o">=</span> <span class="p">(</span><span class="mf">1.0</span> <span class="o">/</span> <span class="n">m</span><span class="p">)</span> <span class="o">*</span> <span class="n">d_z</span>

     <span class="n">loss</span> <span class="o">=</span> <span class="o">-</span><span class="p">((</span><span class="n">y_curr</span> <span class="o">*</span> <span class="n">log</span><span class="p">(</span><span class="n">y_hat</span><span class="p">))</span> <span class="o">+</span> <span class="p">((</span><span class="mf">1.0</span> <span class="o">+</span> <span class="n">y_curr</span><span class="p">)</span> <span class="o">*</span> <span class="n">log</span><span class="p">(</span><span class="mf">1.0</span> <span class="o">-</span> <span class="n">y_hat</span><span class="p">)))</span>

     <span class="n">w_out_i</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">d_w</span><span class="o">.</span><span class="n">x</span>
     <span class="n">w_out_j</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">d_w</span><span class="o">.</span><span class="n">y</span>
     <span class="n">b_out</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">d_b</span>
     <span class="n">l_out</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">loss</span>


 <span class="c1"># First we create input and ouput tensors for shader</span>
 <span class="n">tensor_x_i</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">([</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">])</span>
 <span class="n">tensor_x_j</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">([</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">])</span>

 <span class="n">tensor_y</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">([</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">])</span>

 <span class="n">tensor_w_in</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">([</span><span class="mf">0.001</span><span class="p">,</span> <span class="mf">0.001</span><span class="p">])</span>
 <span class="n">tensor_w_out_i</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">([</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">])</span>
 <span class="n">tensor_w_out_j</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">([</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">])</span>

 <span class="n">tensor_b_in</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">([</span><span class="mf">0.0</span><span class="p">])</span>
 <span class="n">tensor_b_out</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">([</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">])</span>

 <span class="n">tensor_l_out</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">([</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">])</span>

 <span class="n">tensor_m</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">([</span> <span class="mf">5.0</span> <span class="p">])</span>

 <span class="c1"># We store them in an array for easier interaction</span>
 <span class="n">params</span> <span class="o">=</span> <span class="p">[</span><span class="n">tensor_x_i</span><span class="p">,</span> <span class="n">tensor_x_j</span><span class="p">,</span> <span class="n">tensor_y</span><span class="p">,</span> <span class="n">tensor_w_in</span><span class="p">,</span> <span class="n">tensor_w_out_i</span><span class="p">,</span>
     <span class="n">tensor_w_out_j</span><span class="p">,</span> <span class="n">tensor_b_in</span><span class="p">,</span> <span class="n">tensor_b_out</span><span class="p">,</span> <span class="n">tensor_l_out</span><span class="p">,</span> <span class="n">tensor_m</span><span class="p">]</span>

 <span class="n">mgr</span> <span class="o">=</span> <span class="n">Manager</span><span class="p">()</span>

 <span class="n">mgr</span><span class="o">.</span><span class="n">eval_tensor_create_def</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>

 <span class="c1"># Record commands for efficient evaluation</span>
 <span class="n">sq</span> <span class="o">=</span> <span class="n">mgr</span><span class="o">.</span><span class="n">create_sequence</span><span class="p">()</span>
 <span class="n">sq</span><span class="o">.</span><span class="n">begin</span><span class="p">()</span>
 <span class="n">sq</span><span class="o">.</span><span class="n">record_tensor_sync_device</span><span class="p">([</span><span class="n">tensor_w_in</span><span class="p">,</span> <span class="n">tensor_b_in</span><span class="p">])</span>
 <span class="n">sq</span><span class="o">.</span><span class="n">record_algo_data</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">compute_shader</span><span class="o">.</span><span class="n">to_spirv</span><span class="p">())</span>
 <span class="n">sq</span><span class="o">.</span><span class="n">record_tensor_sync_local</span><span class="p">([</span><span class="n">tensor_w_out_i</span><span class="p">,</span> <span class="n">tensor_w_out_j</span><span class="p">,</span> <span class="n">tensor_b_out</span><span class="p">,</span> <span class="n">tensor_l_out</span><span class="p">])</span>
 <span class="n">sq</span><span class="o">.</span><span class="n">end</span><span class="p">()</span>

 <span class="n">ITERATIONS</span> <span class="o">=</span> <span class="mi">100</span>
 <span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.1</span>

 <span class="c1"># Perform machine learning training and inference across all input X and Y</span>
 <span class="k">for</span> <span class="n">i_iter</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">ITERATIONS</span><span class="p">):</span>
     <span class="n">sq</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>

     <span class="c1"># Calculate the parameters based on the respective derivatives calculated</span>
     <span class="n">w_in_i_val</span> <span class="o">=</span> <span class="n">tensor_w_in</span><span class="o">.</span><span class="n">data</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>
     <span class="n">w_in_j_val</span> <span class="o">=</span> <span class="n">tensor_w_in</span><span class="o">.</span><span class="n">data</span><span class="p">()[</span><span class="mi">1</span><span class="p">]</span>
     <span class="n">b_in_val</span> <span class="o">=</span> <span class="n">tensor_b_in</span><span class="o">.</span><span class="n">data</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>

     <span class="k">for</span> <span class="n">j_iter</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">tensor_b_out</span><span class="o">.</span><span class="n">size</span><span class="p">()):</span>
         <span class="n">w_in_i_val</span> <span class="o">-=</span> <span class="n">learning_rate</span> <span class="o">*</span> <span class="n">tensor_w_out_i</span><span class="o">.</span><span class="n">data</span><span class="p">()[</span><span class="n">j_iter</span><span class="p">]</span>
         <span class="n">w_in_j_val</span> <span class="o">-=</span> <span class="n">learning_rate</span> <span class="o">*</span> <span class="n">tensor_w_out_j</span><span class="o">.</span><span class="n">data</span><span class="p">()[</span><span class="n">j_iter</span><span class="p">]</span>
         <span class="n">b_in_val</span> <span class="o">-=</span> <span class="n">learning_rate</span> <span class="o">*</span> <span class="n">tensor_b_out</span><span class="o">.</span><span class="n">data</span><span class="p">()[</span><span class="n">j_iter</span><span class="p">]</span>

     <span class="c1"># Update the parameters to process inference again</span>
     <span class="n">tensor_w_in</span><span class="o">.</span><span class="n">set_data</span><span class="p">([</span><span class="n">w_in_i_val</span><span class="p">,</span> <span class="n">w_in_j_val</span><span class="p">])</span>
     <span class="n">tensor_b_in</span><span class="o">.</span><span class="n">set_data</span><span class="p">([</span><span class="n">b_in_val</span><span class="p">])</span>

 <span class="k">assert</span> <span class="n">tensor_w_in</span><span class="o">.</span><span class="n">data</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&lt;</span> <span class="mf">0.01</span>
 <span class="k">assert</span> <span class="n">tensor_w_in</span><span class="o">.</span><span class="n">data</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mf">0.0</span>
 <span class="k">assert</span> <span class="n">tensor_w_in</span><span class="o">.</span><span class="n">data</span><span class="p">()[</span><span class="mi">1</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mf">1.5</span>
 <span class="k">assert</span> <span class="n">tensor_b_in</span><span class="o">.</span><span class="n">data</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&lt;</span> <span class="mf">0.7</span>

 <span class="c1"># Print outputs</span>
 <span class="nb">print</span><span class="p">(</span><span class="n">tensor_w_in</span><span class="o">.</span><span class="n">data</span><span class="p">())</span>
 <span class="nb">print</span><span class="p">(</span><span class="n">tensor_b_in</span><span class="o">.</span><span class="n">data</span><span class="p">())</span>
</pre></div>
</td></tr></table></div>


<h2 id="log-level-configuration">Log Level Configuration<a class="headerlink" href="#log-level-configuration" title="Permalink to this headline">¶</a></h2>
<p>You can configure log level with the function <cite>kp.log_level</cite> as outlined below.</p>
<p>The values are TRACE=0, DEBUG=1, INFO=2, WARN=3, ERROR=4. Kompute defaults to INFO.</p>
<div class="highlight-python notranslate"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2</pre></div></td><td class="code"><div class="highlight"><pre><span></span> <span class="kn">import</span> <span class="nn">kp</span>
 <span class="n">kp</span><span class="o">.</span><span class="n">log_level</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</td></tr></table></div>




          </article>
        </div>
      </div>
    </main>
  </div>
  <footer class="md-footer">
    <div class="md-footer-nav">
      <nav class="md-footer-nav__inner md-grid">
          
            <a href="advanced-examples.html" title="Examples"
               class="md-flex md-footer-nav__link md-footer-nav__link--prev"
               rel="prev">
              <div class="md-flex__cell md-flex__cell--shrink">
                <i class="md-icon md-icon--arrow-back md-footer-nav__button"></i>
              </div>
              <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title">
                <span class="md-flex__ellipsis">
                  <span
                      class="md-footer-nav__direction"> Previous </span> Examples </span>
              </div>
            </a>
          
          
            <a href="async-parallel.html" title="Asynchronous and Parallel Operations"
               class="md-flex md-footer-nav__link md-footer-nav__link--next"
               rel="next">
            <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title"><span
                class="md-flex__ellipsis"> <span
                class="md-footer-nav__direction"> Next </span> Asynchronous and Parallel Operations </span>
            </div>
            <div class="md-flex__cell md-flex__cell--shrink"><i
                class="md-icon md-icon--arrow-forward md-footer-nav__button"></i>
            </div>
          
        </a>
        
      </nav>
    </div>
    <div class="md-footer-meta md-typeset">
      <div class="md-footer-meta__inner md-grid">
        <div class="md-footer-copyright">
          <div class="md-footer-copyright__highlight">
              &#169; Copyright 2020, The Institute for Ethical AI &amp; Machine Learning.
              
          </div>
            Created using
            <a href="http://www.sphinx-doc.org/">Sphinx</a> 3.2.1.
             and
            <a href="https://github.com/bashtage/sphinx-material/">Material for
              Sphinx</a>
        </div>
      </div>
    </div>
  </footer>
  <script src="../_static/javascripts/application.js"></script>
  <script>app.initialize({version: "1.0.4", url: {base: ".."}})</script>
  </body>
</html>