<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">

<html lang="en">

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <title>LCOV - lcov.info - test/TestLogisticRegression.cpp</title>
  <link rel="stylesheet" type="text/css" href="../gcov.css">
</head>

<body>

  <table width="100%" border=0 cellspacing=0 cellpadding=0>
    <tr><td class="title">LCOV - code coverage report</td></tr>
    <tr><td class="ruler"><img src="../glass.png" width=3 height=3 alt=""></td></tr>

    <tr>
      <td width="100%">
        <table cellpadding=1 border=0 width="100%">
          <tr>
            <td width="10%" class="headerItem">Current view:</td>
            <td width="35%" class="headerValue"><a href="../index.html">top level</a> - <a href="index.html">test</a> - TestLogisticRegression.cpp<span style="font-size: 80%;"> (source / <a href="TestLogisticRegression.cpp.func-sort-c.html">functions</a>)</span></td>
            <td width="5%"></td>
            <td width="15%"></td>
            <td width="10%" class="headerCovTableHead">Hit</td>
            <td width="10%" class="headerCovTableHead">Total</td>
            <td width="15%" class="headerCovTableHead">Coverage</td>
          </tr>
          <tr>
            <td class="headerItem">Test:</td>
            <td class="headerValue">lcov.info</td>
            <td></td>
            <td class="headerItem">Lines:</td>
            <td class="headerCovTableEntry">65</td>
            <td class="headerCovTableEntry">65</td>
            <td class="headerCovTableEntryHi">100.0 %</td>
          </tr>
          <tr>
            <td class="headerItem">Date:</td>
            <td class="headerValue">2021-02-13 13:13:47</td>
            <td></td>
            <td class="headerItem">Functions:</td>
            <td class="headerCovTableEntry">6</td>
            <td class="headerCovTableEntry">8</td>
            <td class="headerCovTableEntryMed">75.0 %</td>
          </tr>
          <tr><td><img src="../glass.png" width=3 height=3 alt=""></td></tr>
        </table>
      </td>
    </tr>

    <tr><td class="ruler"><img src="../glass.png" width=3 height=3 alt=""></td></tr>
  </table>

  <table cellpadding=0 cellspacing=0 border=0>
    <tr>
      <td><br></td>
    </tr>
    <tr>
      <td>
<pre class="sourceHeading">          Line data    Source code</pre>
<pre class="source">
<a name="1"><span class="lineNum">       1 </span>            : </a>
<span class="lineNum">       2 </span>            : #include &quot;gtest/gtest.h&quot;
<span class="lineNum">       3 </span>            : 
<span class="lineNum">       4 </span>            : #include &quot;kompute/Kompute.hpp&quot;
<span class="lineNum">       5 </span>            : 
<a name="6"><span class="lineNum">       6 </span>            : #include &quot;kompute_test/shaders/shadertest_logistic_regression.hpp&quot;</a>
<span class="lineNum">       7 </span>            : 
<span class="lineNum">       8 </span><span class="lineCov">         43 : TEST(TestLogisticRegressionAlgorithm, TestMainLogisticRegression)</span>
<span class="lineNum">       9 </span>            : {
<span class="lineNum">      10 </span>            : 
<span class="lineNum">      11 </span>            :     uint32_t ITERATIONS = 100;
<span class="lineNum">      12 </span>            :     float learningRate = 0.1;
<span class="lineNum">      13 </span>            : 
<span class="lineNum">      14 </span><span class="lineCov">          2 :     std::shared_ptr&lt;kp::Tensor&gt; xI{ new kp::Tensor({ 0, 1, 1, 1, 1 }) };</span>
<span class="lineNum">      15 </span><span class="lineCov">          2 :     std::shared_ptr&lt;kp::Tensor&gt; xJ{ new kp::Tensor({ 0, 0, 0, 1, 1 }) };</span>
<span class="lineNum">      16 </span>            : 
<span class="lineNum">      17 </span><span class="lineCov">          2 :     std::shared_ptr&lt;kp::Tensor&gt; y{ new kp::Tensor({ 0, 0, 0, 1, 1 }) };</span>
<span class="lineNum">      18 </span>            : 
<span class="lineNum">      19 </span><span class="lineCov">          2 :     std::shared_ptr&lt;kp::Tensor&gt; wIn{ new kp::Tensor({ 0.001, 0.001 }) };</span>
<span class="lineNum">      20 </span><span class="lineCov">          2 :     std::shared_ptr&lt;kp::Tensor&gt; wOutI{ new kp::Tensor({ 0, 0, 0, 0, 0 }) };</span>
<span class="lineNum">      21 </span><span class="lineCov">          2 :     std::shared_ptr&lt;kp::Tensor&gt; wOutJ{ new kp::Tensor({ 0, 0, 0, 0, 0 }) };</span>
<span class="lineNum">      22 </span>            : 
<span class="lineNum">      23 </span><span class="lineCov">          2 :     std::shared_ptr&lt;kp::Tensor&gt; bIn{ new kp::Tensor({ 0 }) };</span>
<span class="lineNum">      24 </span><span class="lineCov">          2 :     std::shared_ptr&lt;kp::Tensor&gt; bOut{ new kp::Tensor({ 0, 0, 0, 0, 0 }) };</span>
<span class="lineNum">      25 </span>            : 
<span class="lineNum">      26 </span><span class="lineCov">          2 :     std::shared_ptr&lt;kp::Tensor&gt; lOut{ new kp::Tensor({ 0, 0, 0, 0, 0 }) };</span>
<span class="lineNum">      27 </span>            : 
<span class="lineNum">      28 </span>            :     std::vector&lt;std::shared_ptr&lt;kp::Tensor&gt;&gt; params = { xI,  xJ,    y,
<span class="lineNum">      29 </span>            :                                                         wIn, wOutI, wOutJ,
<span class="lineNum">      30 </span><span class="lineCov">          3 :                                                         bIn, bOut,  lOut };</span>
<span class="lineNum">      31 </span>            : 
<span class="lineNum">      32 </span>            :     {
<span class="lineNum">      33 </span><span class="lineCov">          2 :         kp::Manager mgr;</span>
<span class="lineNum">      34 </span>            : 
<span class="lineNum">      35 </span><span class="lineCov">          1 :         mgr.rebuild(params);</span>
<span class="lineNum">      36 </span>            : 
<span class="lineNum">      37 </span><span class="lineCov">          2 :         std::shared_ptr&lt;kp::Sequence&gt; sq = mgr.sequence();</span>
<span class="lineNum">      38 </span>            : 
<span class="lineNum">      39 </span>            :         // Record op algo base
<span class="lineNum">      40 </span><span class="lineCov">          1 :         sq-&gt;begin();</span>
<span class="lineNum">      41 </span>            : 
<span class="lineNum">      42 </span><span class="lineCov">          2 :         sq-&gt;record&lt;kp::OpTensorSyncDevice&gt;({ wIn, bIn });</span>
<span class="lineNum">      43 </span>            : 
<span class="lineNum">      44 </span>            : #ifdef KOMPUTE_SHADER_FROM_STRING
<span class="lineNum">      45 </span>            :         sq-&gt;record&lt;kp::OpAlgoBase&gt;(
<span class="lineNum">      46 </span>            :           params, &quot;test/shaders/glsl/test_logistic_regression.comp.spv&quot;);
<span class="lineNum">      47 </span>            : #else
<span class="lineNum">      48 </span><span class="lineCov">          1 :         sq-&gt;record&lt;kp::OpAlgoBase&gt;(</span>
<span class="lineNum">      49 </span>            :           params,
<span class="lineNum">      50 </span><span class="lineCov">          2 :           std::vector&lt;char&gt;(</span>
<span class="lineNum">      51 </span>            :             kp::shader_data::shaders_glsl_logisticregression_comp_spv,
<span class="lineNum">      52 </span>            :             kp::shader_data::shaders_glsl_logisticregression_comp_spv +
<span class="lineNum">      53 </span>            :               kp::shader_data::shaders_glsl_logisticregression_comp_spv_len));
<span class="lineNum">      54 </span>            : #endif
<span class="lineNum">      55 </span>            : 
<span class="lineNum">      56 </span><span class="lineCov">          2 :         sq-&gt;record&lt;kp::OpTensorSyncLocal&gt;({ wOutI, wOutJ, bOut, lOut });</span>
<span class="lineNum">      57 </span>            : 
<span class="lineNum">      58 </span><span class="lineCov">          1 :         sq-&gt;end();</span>
<span class="lineNum">      59 </span>            : 
<span class="lineNum">      60 </span>            :         // Iterate across all expected iterations
<span class="lineNum">      61 </span><span class="lineCov">        201 :         for (size_t i = 0; i &lt; ITERATIONS; i++) {</span>
<span class="lineNum">      62 </span>            : 
<span class="lineNum">      63 </span><span class="lineCov">        100 :             sq-&gt;eval();</span>
<span class="lineNum">      64 </span>            : 
<span class="lineNum">      65 </span><span class="lineCov">       1100 :             for (size_t j = 0; j &lt; bOut-&gt;size(); j++) {</span>
<span class="lineNum">      66 </span><span class="lineCov">       1500 :                 wIn-&gt;data()[0] -= learningRate * wOutI-&gt;data()[j];</span>
<span class="lineNum">      67 </span><span class="lineCov">       1500 :                 wIn-&gt;data()[1] -= learningRate * wOutJ-&gt;data()[j];</span>
<span class="lineNum">      68 </span><span class="lineCov">       1500 :                 bIn-&gt;data()[0] -= learningRate * bOut-&gt;data()[j];</span>
<span class="lineNum">      69 </span>            :             }
<span class="lineNum">      70 </span>            :         }
<span class="lineNum">      71 </span>            :     }
<span class="lineNum">      72 </span>            : 
<span class="lineNum">      73 </span>            :     // Based on the inputs the outputs should be at least:
<span class="lineNum">      74 </span>            :     // * wi &lt; 0.01
<span class="lineNum">      75 </span>            :     // * wj &gt; 1.0
<span class="lineNum">      76 </span>            :     // * b &lt; 0
<span class="lineNum">      77 </span>            :     // TODO: Add EXPECT_DOUBLE_EQ instead
<span class="lineNum">      78 </span><span class="lineCov">          2 :     EXPECT_LT(wIn-&gt;data()[0], 0.01);</span>
<span class="lineNum">      79 </span><span class="lineCov">          3 :     EXPECT_GT(wIn-&gt;data()[1], 1.0);</span>
<span class="lineNum">      80 </span><span class="lineCov">          2 :     EXPECT_LT(bIn-&gt;data()[0], 0.0);</span>
<span class="lineNum">      81 </span>            : 
<span class="lineNum">      82 </span><span class="lineCov">          4 :     SPDLOG_WARN(&quot;Result wIn i: {}, wIn j: {}, bIn: {}&quot;,</span>
<span class="lineNum">      83 </span>            :                 wIn-&gt;data()[0],
<span class="lineNum">      84 </span>            :                 wIn-&gt;data()[1],
<span class="lineNum">      85 </span>            :                 bIn-&gt;data()[0]);
<a name="86"><span class="lineNum">      86 </span><span class="lineCov">          1 : }</span></a>
<span class="lineNum">      87 </span>            : 
<span class="lineNum">      88 </span><span class="lineCov">         43 : TEST(TestLogisticRegressionAlgorithm, TestMainLogisticRegressionManualCopy)</span>
<span class="lineNum">      89 </span>            : {
<span class="lineNum">      90 </span>            : 
<span class="lineNum">      91 </span>            :     uint32_t ITERATIONS = 100;
<span class="lineNum">      92 </span>            :     float learningRate = 0.1;
<span class="lineNum">      93 </span>            : 
<span class="lineNum">      94 </span><span class="lineCov">          1 :     std::vector&lt;float&gt; wInVec = { 0.001, 0.001 };</span>
<span class="lineNum">      95 </span><span class="lineCov">          1 :     std::vector&lt;float&gt; bInVec = { 0 };</span>
<span class="lineNum">      96 </span>            : 
<span class="lineNum">      97 </span><span class="lineCov">          2 :     std::shared_ptr&lt;kp::Tensor&gt; xI{ new kp::Tensor({ 0, 1, 1, 1, 1 }) };</span>
<span class="lineNum">      98 </span><span class="lineCov">          2 :     std::shared_ptr&lt;kp::Tensor&gt; xJ{ new kp::Tensor({ 0, 0, 0, 1, 1 }) };</span>
<span class="lineNum">      99 </span>            : 
<span class="lineNum">     100 </span><span class="lineCov">          2 :     std::shared_ptr&lt;kp::Tensor&gt; y{ new kp::Tensor({ 0, 0, 0, 1, 1 }) };</span>
<span class="lineNum">     101 </span>            : 
<span class="lineNum">     102 </span>            :     std::shared_ptr&lt;kp::Tensor&gt; wIn{ new kp::Tensor(
<span class="lineNum">     103 </span><span class="lineCov">          1 :       wInVec, kp::Tensor::TensorTypes::eHost) };</span>
<span class="lineNum">     104 </span><span class="lineCov">          2 :     std::shared_ptr&lt;kp::Tensor&gt; wOutI{ new kp::Tensor({ 0, 0, 0, 0, 0 }) };</span>
<span class="lineNum">     105 </span><span class="lineCov">          2 :     std::shared_ptr&lt;kp::Tensor&gt; wOutJ{ new kp::Tensor({ 0, 0, 0, 0, 0 }) };</span>
<span class="lineNum">     106 </span>            : 
<span class="lineNum">     107 </span>            :     std::shared_ptr&lt;kp::Tensor&gt; bIn{ new kp::Tensor(
<span class="lineNum">     108 </span><span class="lineCov">          1 :       bInVec, kp::Tensor::TensorTypes::eHost) };</span>
<span class="lineNum">     109 </span><span class="lineCov">          2 :     std::shared_ptr&lt;kp::Tensor&gt; bOut{ new kp::Tensor({ 0, 0, 0, 0, 0 }) };</span>
<span class="lineNum">     110 </span>            : 
<span class="lineNum">     111 </span><span class="lineCov">          2 :     std::shared_ptr&lt;kp::Tensor&gt; lOut{ new kp::Tensor({ 0, 0, 0, 0, 0 }) };</span>
<span class="lineNum">     112 </span>            : 
<span class="lineNum">     113 </span>            :     std::vector&lt;std::shared_ptr&lt;kp::Tensor&gt;&gt; params = { xI,  xJ,    y,
<span class="lineNum">     114 </span>            :                                                         wIn, wOutI, wOutJ,
<span class="lineNum">     115 </span><span class="lineCov">          3 :                                                         bIn, bOut,  lOut };</span>
<span class="lineNum">     116 </span>            : 
<span class="lineNum">     117 </span>            :     {
<span class="lineNum">     118 </span><span class="lineCov">          2 :         kp::Manager mgr;</span>
<span class="lineNum">     119 </span>            : 
<span class="lineNum">     120 </span><span class="lineCov">          1 :         mgr.rebuild(params);</span>
<span class="lineNum">     121 </span>            : 
<span class="lineNum">     122 </span><span class="lineCov">          2 :         std::shared_ptr&lt;kp::Sequence&gt; sq = mgr.sequence();</span>
<span class="lineNum">     123 </span>            : 
<span class="lineNum">     124 </span>            :         // Record op algo base
<span class="lineNum">     125 </span><span class="lineCov">          1 :         sq-&gt;begin();</span>
<span class="lineNum">     126 </span>            : 
<span class="lineNum">     127 </span>            : #ifdef KOMPUTE_SHADER_FROM_STRING
<span class="lineNum">     128 </span>            :         sq-&gt;record&lt;kp::OpAlgoBase&gt;(
<span class="lineNum">     129 </span>            :           params, &quot;test/shaders/glsl/test_logistic_regression.comp.spv&quot;);
<span class="lineNum">     130 </span>            : #else
<span class="lineNum">     131 </span><span class="lineCov">          1 :         sq-&gt;record&lt;kp::OpAlgoBase&gt;(</span>
<span class="lineNum">     132 </span>            :           params,
<span class="lineNum">     133 </span><span class="lineCov">          2 :           std::vector&lt;char&gt;(</span>
<span class="lineNum">     134 </span>            :             kp::shader_data::shaders_glsl_logisticregression_comp_spv,
<span class="lineNum">     135 </span>            :             kp::shader_data::shaders_glsl_logisticregression_comp_spv +
<span class="lineNum">     136 </span>            :               kp::shader_data::shaders_glsl_logisticregression_comp_spv_len));
<span class="lineNum">     137 </span>            : #endif
<span class="lineNum">     138 </span>            : 
<span class="lineNum">     139 </span><span class="lineCov">          2 :         sq-&gt;record&lt;kp::OpTensorSyncLocal&gt;({ wOutI, wOutJ, bOut, lOut });</span>
<span class="lineNum">     140 </span>            : 
<span class="lineNum">     141 </span><span class="lineCov">          1 :         sq-&gt;end();</span>
<span class="lineNum">     142 </span>            : 
<span class="lineNum">     143 </span>            :         // Iterate across all expected iterations
<span class="lineNum">     144 </span><span class="lineCov">        201 :         for (size_t i = 0; i &lt; ITERATIONS; i++) {</span>
<span class="lineNum">     145 </span>            : 
<span class="lineNum">     146 </span><span class="lineCov">        100 :             sq-&gt;eval();</span>
<span class="lineNum">     147 </span>            : 
<span class="lineNum">     148 </span><span class="lineCov">       1100 :             for (size_t j = 0; j &lt; bOut-&gt;size(); j++) {</span>
<span class="lineNum">     149 </span><span class="lineCov">       1500 :                 wIn-&gt;data()[0] -= learningRate * wOutI-&gt;data()[j];</span>
<span class="lineNum">     150 </span><span class="lineCov">       1500 :                 wIn-&gt;data()[1] -= learningRate * wOutJ-&gt;data()[j];</span>
<span class="lineNum">     151 </span><span class="lineCov">       1500 :                 bIn-&gt;data()[0] -= learningRate * bOut-&gt;data()[j];</span>
<span class="lineNum">     152 </span>            :             }
<span class="lineNum">     153 </span><span class="lineCov">        100 :             wIn-&gt;mapDataIntoHostMemory();</span>
<span class="lineNum">     154 </span><span class="lineCov">        100 :             bIn-&gt;mapDataIntoHostMemory();</span>
<span class="lineNum">     155 </span>            :         }
<span class="lineNum">     156 </span>            :     }
<span class="lineNum">     157 </span>            : 
<span class="lineNum">     158 </span>            :     // Based on the inputs the outputs should be at least:
<span class="lineNum">     159 </span>            :     // * wi &lt; 0.01
<span class="lineNum">     160 </span>            :     // * wj &gt; 1.0
<span class="lineNum">     161 </span>            :     // * b &lt; 0
<span class="lineNum">     162 </span>            :     // TODO: Add EXPECT_DOUBLE_EQ instead
<span class="lineNum">     163 </span><span class="lineCov">          2 :     EXPECT_LT(wIn-&gt;data()[0], 0.01);</span>
<span class="lineNum">     164 </span><span class="lineCov">          3 :     EXPECT_GT(wIn-&gt;data()[1], 1.0);</span>
<span class="lineNum">     165 </span><span class="lineCov">          2 :     EXPECT_LT(bIn-&gt;data()[0], 0.0);</span>
<span class="lineNum">     166 </span>            : 
<span class="lineNum">     167 </span><span class="lineCov">          4 :     SPDLOG_WARN(&quot;Result wIn i: {}, wIn j: {}, bIn: {}&quot;,</span>
<span class="lineNum">     168 </span>            :                 wIn-&gt;data()[0],
<a name="169"><span class="lineNum">     169 </span>            :                 wIn-&gt;data()[1],</a>
<span class="lineNum">     170 </span>            :                 bIn-&gt;data()[0]);
<span class="lineNum">     171 </span><span class="lineCov">         25 : }</span>
</pre>
      </td>
    </tr>
  </table>
  <br>

  <table width="100%" border=0 cellspacing=0 cellpadding=0>
    <tr><td class="ruler"><img src="../glass.png" width=3 height=3 alt=""></td></tr>
    <tr><td class="versionInfo">Generated by: <a href="http://ltp.sourceforge.net/coverage/lcov.php" target="_parent">LCOV version 1.13</a></td></tr>
  </table>
  <br>

</body>
</html>
